---
title: "Methodology"
permalink: /topics/methodology/
excerpt: "Our methodology"
last_modified_at: 2022-07-03T12:00:00-00:00
toc: true
references: true
---

## Our methodology

Below are the core principles we try to follow. This might change over time as we steelman the techniques but we had to start somewhere.

1. Use structured reasons and arguments ([Dutilh Novaes & Zalta, 2021](#Dutilh_Novaes_&_Zalta,_2021)).
2. If possible, use arguments based on evidence ([Kelly & Zalta, 2016](#Kelly_&_Zalta,_2016)), science ([Hepburn et al., 2021](#Hepburn_et_al.,_2021)), and rationalism ([Markie et al., 2021](#Markie_et_al.,_2021)).
3. Use a hierarchy of evidence ([Schünemann et al., 2022](#Schunemann_et_al.,_2022)) that generally values certain types of evidence higher than others in the following order:
    1. Experimental studies ([Franklin et al., 2021](#Franklin_et_al.,_2021)) by experts in peer-reviewed, scientific journals
        1. Meta-analyses and systematic reviews ([Lasserson et al., 2022](Lasserson_et_al.,_2022)) of the following types of studies
        2. Randomized controlled trial (RCT) experiments ([Reiss et al., 2022](#Reiss_et_al.,_2022)): Patients are randomly assigned to an intervention group or a control group (not receiving the intervention) and the groups are compared, hopefully controlling for confounding variables ([Lu, 2009](#Lu,_2009)):
             1. Placebo-controlled: A placebo is assumed to have no or minimal effect
             2. Non-placebo-controlled
             3. Versions of the above two types:
                 1. Triple blinded (patient, experimenters, and data analyst)
                 2. Double blinded (patient and experimenters)
                 3. Single blinded (patient)
                 4. Unblinded
        2. Experiments without a control group
            1. Experiments on groups
            2. Experiments on individuals (case studies)
        3. Experiments exploring a mechanism of action ([Craver et al., 2019](#Craver_et_al.,_2019))
    2. Correlational/observational studies by experts in peer-reviewed, scientific journals
        1. Meta-analyses and systematic reviews of the following types of studies
        2. Cohort studies ([Euser et al., 2009](#Euser_et_al.,_2009)): Follow one exposed group and a non-exposed group (control) and compare outcomes.
            1. Prospective: Baseline is assessed and then researchers actively follow patients to perform a follow-up: More accurate data collection
            2. Retrospective: Historical analysis of existing data
        3. Case-control studies ([Lu, 2009](#Lu,_2009)): Follow one group with an outcome and another without an outcome (control) and compare exposure.
        4. Cross-sectional studies ([Lu, 2009](#Lu,_2009)): Analyze whether individuals were exposed and whether they had certain outcomes and compare to those that didn't (control).
        5. Observations without a control group
            1. Observations of groups
            2. Observations of individuals (case studies)
        6. Ecological studies ([Lu, 2009](#Lu,_2009)): Similar to cross-sectional studies but groups are analyzed instead of individuals
    3. Simulated model ([Frigg et al., 2020](#Frigg_et_al.,_2020)) results by experts in peer-reviewed, scientific journals
    4. Opinions by experts in peer-reviewed, scientific journals
        1. Groups of experts
        2. Individual experts
    5. All of the above but not in peer-reviewed, scientific journals
    6. All of the above but not by experts

### Other general points

1. We use the heuristic that mistakes are generally made due to incompetence rather than malice ([Bloch, 2003](#Bloch,_2003)), although the latter is certainly possible.
1. When comparing arguments, the number of points doesn't necessarily matter.

### Caveats

1. There are potential issues with the concept of a hierarchy of evidence ([Stegenga, 2018](#Stegenga,_2018); [Blunt, 2015](#Blunt,_2015)).
1. A lack of evidence higher in the hierarchy is not necessarily problematic due to [infeasibility][Smith & Pell, 2003], ethical issues, etc.
1. There are potential issues with specific types of evidence; for examples:
    1. RCTs: Simpson's Paradox ([Sprenger et al., 2021](#Sprenger_et_al.,_2021))
1. In some cases, evidence lower in the hierarchy may be stronger; for example, a well-done experiment might be stronger than a poorly done RCT.
1. There are potential issues with all types of evidence ([Ioannidis, 2005](#Ioannidis,_2005)); for examples:
    1. Lacking or poor reproduction, or too much reproduction ([Ioannidis & Trikalinos, 2007](#Ioannidis_&_Trikalinos,_2007))
    1. Statistically significant but false effects due to low statistical power ([Button et al., 2013](#Button_et_al.,_2013))
    1. Small effect sizes
    1. Poor study design or methodology
    1. Poor external validity ([Reiss et al., 2022](#Reiss_et_al.,_2022))
    1. Biases (conflicts of interest, funding sources, etc.)
    1. Mistakes (data entry, variable coding, statistics, over-interpretation, etc.)
    1. Multiple comparisons ([Bennett et al., 2009](#Bennett_et_al.,_2009))
    1. p-hacking, researcher degrees of freedom, multiple potential comparisons, or fishing expeditions ([Simmons et al., 2016](#Simmons_et_al.,_2016); [Humphreys et al., 2013](#Humphreys_et_al.,_2013); [Gelman & Loken, 2013](#Gelman_&_Loken,_2013))
    1. Poor incentives ([Nosek et al., 2012](#Nosek_et_al.,_2012))
    1. Poor instrument or method reliability ([Vul et al., 2009](#Vul_et_al.,_2009))
    1. Fraud

<!-- References -->

[Bennett et al., 2009]: https://tauruspet.med.yale.edu/staff/edm42/courses/ENAS_880_2018/papers/Bennett-Salmon-2009.pdf 'Bennett, C. M., Baird, A. A., Miller, M. B., and Wolford, G. L. (2009). Neural correlates of interspecies perspective taking in the post-mortem Atlantic Salmon: An argument for multiple comparisons correction. Poster presented at Human Brain Mapping conference. https://tauruspet.med.yale.edu/staff/edm42/courses/ENAS_880_2018/papers/Bennett-Salmon-2009.pdf'
[Bloch, 2003]: https://archive.org/details/murphyslawbooktw00bloc/page/52/mode/2up 'Bloch, A. (2003). Murphy's law. Penguin. https://archive.org/details/murphyslawbooktw00bloc/page/52/mode/2up'
[Blunt, 2015]: https://etheses.lse.ac.uk/3284/1/Blunt_heirachies_of_evidence.pdf 'Blunt, C. (2015). Hierarchies of evidence in evidence-based medicine (Doctoral dissertation, London School of Economics and Political Science). Retrieved July 3, 2022, from https://etheses.lse.ac.uk/3284/1/Blunt_heirachies_of_evidence.pdf'
[Button et al., 2013]: https://www.nature.com/articles/nrn3475.pdf 'Button, K. S., Ioannidis, J., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature reviews neuroscience, 14(5), 365-376. https://doi.org/10.1038/nrn3475'
[Craver et al., 2019]: https://plato.stanford.edu/entries/science-mechanisms/ 'Craver, C., Tabery, J., & Zalta, E. (Ed.) (2019). Mechanisms in Science. The Stanford Encyclopedia of Philosophy (Summer 2019 Edition). https://plato.stanford.edu/archives/sum2019/entries/science-mechanisms/'
[Dutilh Novaes & Zalta, 2021]: https://plato.stanford.edu/entries/argument/ 'Dutilh Novaes, C., & Zalta, E. (Ed.) (2021). Argument and Argumentation. The Stanford Encyclopedia of Philosophy (Fall 2021 Edition). https://plato.stanford.edu/archives/fall2021/entries/argument/'
[Euser et al., 2009]: https://doi.org/10.1159/000235241 'Euser, A. M., Zoccali, C., Jager, K. J., & Dekker, F. W. (2009). Cohort studies: prospective versus retrospective. Nephron Clinical Practice, 113(3), c214-c217. https://doi.org/10.1159/000235241'
[Franklin et al., 2021]: https://plato.stanford.edu/entries/physics-experiment/ 'Franklin, A., Perovic, S., & Zalta, E. (Ed.) (2021). Experiment in Physics. The Stanford Encyclopedia of Philosophy (Summer 2021 Edition). https://plato.stanford.edu/archives/sum2021/entries/physics-experiment/'
[Frigg et al., 2020]: https://plato.stanford.edu/entries/models-science/ 'Frigg, R., Hartmann, S., & Zalta, E. (Ed.) (2020). Models in Science. The Stanford Encyclopedia of Philosophy (Spring 2020 Edition). https://plato.stanford.edu/archives/spr2020/entries/models-science/'
[Gelman & Loken, 2013]: https://stat.columbia.edu/~gelman/research/unpublished/forking.pdf '"P-values are a method of protecting researchers from declaring truth based on patterns in noise, and so it is ironic that, by way of data-dependent analyses, p-values are often used to lend credence to noisy claims based on small samples. To put it another way: without modern statistics, we find it unlikely that people would take seriously a claim about the general population of women, based on two survey questions asked to 100 volunteers on the internet and 24 college students. But with the p-value, a result can be declared significant and deemed worth publishing in a leading journal in psychology."&#013;&#013;"absent pre-registration, our data analysis choices will be data-dependent, even when they are motivated directly from theoretical concerns. When pre-registered replication is difficult or impossible (as in much research in social science and public health), we believe the best strategy is to move toward an analysis of all the data rather than a focus on a single comparison or small set of comparisons"&#013;&#013;"In fields where new data can readily be gathered (such as in all four of the examples discussed above), perhaps the two-part structure of Nosek et al. (2013) will be a standard for future research. Instead of the current norm in which several different studies are performed, each with statistical significance but each with analyses that are contingent on data, perhaps researchers can perform half as many original experiments in each paper and just pair each new experiment with a pre-registered replication."&#013;&#013;Gelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348, 1-17. https://stat.columbia.edu/~gelman/research/unpublished/forking.pdf'
[Hepburn et al., 2021]: https://plato.stanford.edu/entries/scientific-method/ 'Hepburn, B., Andersen, H., & Zalta, E. (Ed.) (2021). Scientific Method. The Stanford Encyclopedia of Philosophy (Summer 2021 Edition). https://plato.stanford.edu/archives/sum2021/entries/scientific-method/'
[Humphreys et al., 2013]: https://doi.org/10.1093/pan/mps021 'Humphreys, M., De la Sierra, R. S., & Van der Windt, P. (2013). Fishing, commitment, and communication: A proposal for comprehensive nonbinding research registration. Political Analysis, 21(1), 1-20. https://doi.org/10.1093/pan/mps021'
[Ioannidis, 2005]: https://doi.org/10.1371/journal.pmed.0020124 'Ioannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124. https://doi.org/10.1371/journal.pmed.0020124'
[Ioannidis & Trikalinos, 2007]: https://doi.org/10.1177/1740774507079441 'Ioannidis, J. P., & Trikalinos, T. A. (2007). An exploratory test for an excess of significant findings. Clinical trials, 4(3), 245-253. https://doi.org/10.1177/1740774507079441'
[Kelly & Zalta, 2016]: https://plato.stanford.edu/entries/evidence/ 'Kelly, T., & Zalta, E. (Ed.) (2016). Evidence. The Stanford Encyclopedia of Philosophy (Winter 2016 Edition). https://plato.stanford.edu/archives/win2016/entries/evidence/'
[Lasserson et al., 2022]: https://training.cochrane.org/handbook/current/chapter-01#section-1-1 'Lasserson, TJ., Thomas, J., & Higgins, JPT. (2022). Cochrane handbook for systematic reviews of interventions. Cochrane. Retrieved July 3, 2022, from https://training.cochrane.org/handbook/current/chapter-01#section-1-1'
[Lu, 2009]: https://doi.org/10.1111/j.1742-1241.2009.02056.x 'Lu, C. Y. (2009). Observational studies: a review of study designs, challenges and strategies to reduce confounding. International journal of clinical practice, 63(5), 691-697. https://doi.org/10.1111/j.1742-1241.2009.02056.x'
[Markie et al., 2021]: https://plato.stanford.edu/entries/rationalism-empiricism/ 'Markie, P., Folescu, M., & Zalta, E. (Ed.) (2021). Rationalism vs. Empiricism. The Stanford Encyclopedia of Philosophy (Fall 2021 Edition). https://plato.stanford.edu/archives/fall2021/entries/rationalism-empiricism/'
[Nosek et al., 2012]: https://journals.sagepub.com/doi/pdf/10.1177/1745691612459058 'Nosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615-631. https://doi.org/10.1177/1745691612459058'
[Reiss et al., 2022]: https://plato.stanford.edu/entries/medicine/ 'Reiss, J., Ankeny, R., & Zalta, E. (Ed.) (2022). Philosophy of Medicine. The Stanford Encyclopedia of Philosophy (Summer 2022 Edition). https://plato.stanford.edu/archives/spr2022/entries/medicine/'
[Schunemann et al., 2022]: https://training.cochrane.org/handbook/current/chapter-14#section-14-2 'Schünemann, HJ., Higgins, JPT., Vist, GE., Glasziou, P., Akl, EA., Skoetz, N., & Guyatt, GH. (2022). Cochrane handbook for systematic reviews of interventions. Cochrane. Retrieved July 3, 2022, from https://training.cochrane.org/handbook/current/chapter-14#section-14-2'
[Simmons et al., 2016]: https://journals.sagepub.com/doi/pdf/10.1177/0956797611417632 'Simmons, J. P., Nelson, L. D., & Simonsohn, U. (2016). False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant. https://psycnet.apa.org/doi/10.1037/14805-033'
[Smith & Pell, 2003]: https://doi.org/10.1136/bmj.327.7429.1459 'Smith, G. C., & Pell, J. P. (2003). Parachute use to prevent death and major trauma related to gravitational challenge: systematic review of randomised controlled trials. BMJ, 327(7429), 1459-1461. https://doi.org/10.1136/bmj.327.7429.1459'
[Sprenger et al., 2021]: https://plato.stanford.edu/entries/paradox-simpson/ 'Sprenger, J., Weinberger, N., & Zalta, E. (Ed.) (2021). Simpson's Paradox. The Stanford Encyclopedia of Philosophy (Summer 2021 Edition). https://plato.stanford.edu/archives/sum2021/entries/paradox-simpson/'
[Stegenga, 2018]: https://doi.org/10.1093/oso/9780198747048.001.0001 'Stegenga, J. (2018). Medical nihilism. Oxford University Press. https://doi.org/10.1093/oso/9780198747048.001.0001'
[Vul et al., 2009]: https://doi.org/10.1111/j.1745-6924.2009.01125.x 'Vul, E., Harris, C., Winkielman, P., & Pashler, H. (2009). Puzzlingly high correlations in fMRI studies of emotion, personality, and social cognition. Perspectives on psychological science, 4(3), 274-290. https://doi.org/10.1111/j.1745-6924.2009.01125.x'
