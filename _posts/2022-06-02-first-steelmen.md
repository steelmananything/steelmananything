---
title: "Our First Steelmen"
categories: 
  - Blog
last_modified_at: 2022-06-02T12:00:00-00:00
show_date: true
---

This post is a bit academic, and will be unlike most other posts, but it seems fitting that our first steelmanning exercise should be to consider potential problems with steelmanning itself.

## Steelmanning

As a refresher of [our first post](/blog/welcome/) defining steelmanning, it is another name for the [principle of charity in argumentation][Stevens, 2021] that tries to make the strongest possible argument for someone by [empathizing][Stueber & Zalta, 2019] with their positive intentions. Steelmanning gets its name as the opposite of strawmanning. [Strawmanning][Aikin & Casey, 2011] is an argumentation [fallacy][Hansen & Zalta, 2020] in which a person's argument is made into a man of straw – easy to knock down – and then this strawman is argued against instead of what the person really meant.

## Tinmanning

Before we begin, let’s define another term: [Tinmanning](/topics/introduction/#tinmanning-strawmanning-as-steelmanning).

Tinmanning is a fallacy when someone declares that they’re steelmanning but they’re actually strawmanning.

## Summarizing the terms

* Strawmanning: Making a reasonable argument unreasonable.
* Steelmanning: Making an argument stronger.
* Tinmanning: Someone saying they're steelmanning when they're actually strawmanning.

### Steelmanning may be condescending, harmful, or arrogant

[Ozy Brennan writes](https://thingofthings.wordpress.com/2016/08/09/against-steelmanning/) that when someone declares that they're steelmanning, they're usually [tinmanning](/topics/introduction/#tinmanning-strawmanning-as-steelmanning) and the declaration of steelmanning may be condescending, harmful, or arrogant:

> In the least obnoxious case [...] not only is this person strawmanning you, but they're also acting like you're an idiot and they're so much better than you for being able to think of the argument you actually made.
> 
> [...]
> 
> In the most obnoxious case, Alice doesn't actually understand Bob's argument at all. Often, there are fundamental worldview differences. [...] Instead of understanding that people believe things differently from you, you're transforming everyone into stupider versions of yourself that don't notice the implications of their own beliefs.
> 
> [...]
> 
> You can say "but neither of those are actually steelmanning! Real steelmanning is being able to put other people's viewpoints in words they themselves find more compelling than their own arguments!" However, that is an extraordinarily rare and difficult skill; even most people who do it once can't do it consistently. Saying "to steelman position X..." should be interpreted the same way as saying "to express perfect loving kindness for all beings..." It's certainly a nice ideal which people might want to approach, and some people even manage to pull it off sometimes, but it's a bit arrogant to declare that you're definitely doing it. Even when you think you are, you usually aren't.

First attempt steelmanning Brennan: Even if a person is well-intentioned, steelmanning is very hard to do and thus often leads to [tinmanning](/topics/introduction/#tinmanning-strawmanning-as-steelmanning). Tinmanning may be condescending, harmful, or arrogant. Therefore, declaring that one is steelmanning usually fails and causes unnecessary damage. A better approach is to switch from the debating approach of steelmanning to a collaborative truth-seeking approach, understanding actual viewpoints, and seeking out well-informed advocates.

Response: All forms of truth-seeking are hard and may lead to strawmanning which may lead to being condescending, harmful, or arrogant. The benefit of steelmanning is that it explicitly tries to avoid strawmanning through a foundation of empathy. By analogy, science is very hard, but it's better than the alternatives. The proposed alternative (truth-seeking collaboration, understand actual viewpoints, seek out well-informed advocates, and finding common ground) seems to be part of proper steelmanning.

For more details of this argument, see the [Steelman Anything topic](/topics/introduction/#steelmanning-may-be-condescending-harmful-or-arrogant).

### Steelmanning one argument may strawman another

[Dr. Gelman argues](https://statmodeling.stat.columbia.edu/2022/04/28/the-challenge-of-bending-over-backward-to-see-things-from-the-other-persons-point-of-view/) using two examples by Dr. Alexander that steelmanning one argument may strawman another:

> [Steelmanning] can lead to being uncharitable or "strawmanning" of other positions that are being opposed or caricatured by the people you are steelmanning.

Dr. Gelman's proposed alternative is:

> to try to address the arguments as [they] arise.

First attempt steelmanning Dr. Gelman's argument:

If you steelman an argument of person X, but that person's argument was a strawman of person Y, then you might indirectly worsen that strawman.

Response: Worsening any strawman while steelmanning is a failure of steelmanning; instead, it's [tinmanning](/topics/introduction/#tinmanning-strawmanning-as-steelmanning). By its nature, steelmanning should reduce strawmen, whereas "addressing an argument as it is" does not necessarily reduce strawmen.

Second attempt steelmanning Dr. Gelman's argument:

If what Dr. Alexander did was tinmanning, given that Dr. Alexander is a [major figurehead of the steelmanning movement](https://slatestarcodex.com/2013/02/12/youre-probably-wondering-why-ive-called-you-here-today/), if such an expert steelmans poorly, then something is rotten in steelmanning and we should be skeptical of it.

Response: Dr. Alexander's arguments don't seem to be tinmen. Analyzing both examples:

#### Example 1

Dr. Alexander [wrote](https://astralcodexten.substack.com/p/ivermectin-much-more-than-you-wanted):
   
> Sometimes these people even have a specific theory for why elites are covering up ivermectin, like that pharma companies want you to use more expensive patented drugs instead. This theory is extremely plausible.

Dr. Gelman agrees with a commenter that wrote:

> It's plausible that big pharma might promote expensive therapeutics and suppress information that cheap therapeutics work better. But it's not "extremely plausible" that there's a vast conspiracy among medical researchers (many of whom [stayed] open to the view that ivermectin has some benefit) and public health officials to perpetrate the most significant fraud in human history, with complete disregard for the welfare of tens of millions, as has often been asserted with respect to ivermectin. That wouldn't be an impossibility, but the level of implausibility there is what's important.

Dr. Gelman further writes:

> Alexander was "steelmanning" and bending over backward to understand the position of the people pushing ivermectin, and the other people believing the claims, but in doing so he was swallowing whole a "strawman" about pharmaceutical companies and public health officials.

First, Dr. Alexander never claimed a "vast conspiracy" and such a conspiracy isn't necessary. By analogy, tobacco companies, medical researchers, and public health authorities caused a "significant fraud in human history, with complete disregard for the welfare of tens of millions" in regards to smoking and lung cancer plausibly without a vast conspiracy; instead, it was plausibly due to a mix of greed, [regulatory capture][Nye, 2004], and a science funding system that took a while to find the truth (we will discuss the steelman that this analogy doesn't hold below).

Second, here is the whole context of the Dr. Alexander quote:

> They have a very reasonable-sounding belief, which is that if dozens of studies all say a drug works really well, then it probably works really well. When they see dozens of studies saying a drug works really well, and the elites saying "no don't take it!", their extremely natural conclusion is that it works really well but the elites are covering it up.
> 
> Sometimes these people even have a specific theory for why elites are covering up ivermectin, like that pharma companies want you to use more expensive patented drugs instead. This theory is extremely plausible. Pharma companies are always trying to convince people to use expensive patented drugs instead of equally good generic alternatives. Ivermectin believers probably heard about this from the many, many good articles by responsible news outlets, discussing the many, many times pharma companies have tried to trick people into using more expensive patented medications. Like [this ACSH article about Nexium](https://www.acsh.org/news/2017/01/18/nexium-dark-side-pharma-10546). Or [my article on esketamine](https://slatestarcodex.com/2019/03/11/ketamine-now-by-prescription/). Given that dozens of studies said a drug worked, and elites continued to deny it worked, and there are well-known times where elites lie about drugs in order to make money, it was an incredibly reasonable inference that this was one of those times.

Dr. Alexander's post argues that the scientific studies did show positive results of ivermectin overall, although Dr. Alexander concludes they were confounded by being done in parasite-prone areas:

> The good ivermectin trials in areas with low Strongyloides prevalence, like Vallejos in Argentina, are mostly negative. The good ivermectin trials in areas with high Strongyloides prevalence, like Mahmud in Bangladesh, are mostly positive.
> 
> Worms can't explain the viral positivity outcomes (ie PCR), but Dr. Bitterman suggests that once you remove low quality trials and worm-related results, the rest looks like simple publication bias.
> 
> [...]
> 
> Ivermectin supporters were really wrong.
> 
> [...]
> 
> Mainstream medicine has reacted with slogans like "believe Science". I don't know if those kinds of slogans ever help, but they're especially unhelpful here. A quick look at ivermectin supporters shows their problem is they believed Science too much.

Further:

> I claim that with ivermectin, even the people who don't usually lie were saying it was ineffective, and they were saying it more directly and decisively than liars usually do. [...] And if you don't know which statements about pharmaceuticals are lies, "the one that has dozens of studies contradicting it" is a pretty good heuristic!

Therefore, Dr. Alexander's argument appears to be:

1. Most good ivermectin studies showed positive results.
2. Elites lied about positive ivermectin studies. They weren't simply explaining away the positive results as confounded by parasites, but they were denying the positive results outright.
3. Ivermectin is a cheap drug compared to those owned and promoted by elites.
4. Therefore, it's extremely plausible for an average person to think that elites covered up ivermectin to make more money.
5. That ivermectin might have shown positive results due to confounding is irrelevant because that's an argument almost no one was making.

One could argue that the above is a tinman: Given the added global scrutiny by medical researchers and public health officials, a better steelman would be a simpler explanation of incompetence and myopia, along with greed combined with regulatory capture.

However, Dr. Alexander argues that this doesn't explain the active disregard for the positive evidence of ivermectin studies. One would seemingly need to argue something along the lines of:

1. Medical researchers and public health officials were aware of the positive evidence of ivermectin studies. They may have thought the evidence was inconclusive, required larger experiments, or simply thought the vaccines were a more likely path to containment in an emergency situation.
2. They wanted to focus on what they thought was the most likely path to containment and not introduce complexity which could be misinterpreted.
3. Therefore, they lied to the public about ivermectin studies.
4. That this could lead to increased profits for pharmaceutical companies and overreactions in popular culture would be incidental to the broader goal of saving the most people.

This sort of medical Machiavellianism is plausible and potentially justifiable, but it's not clearly much more plausible than Dr. Alexander's argument, especially given the history of scientific incompetence and regulatory capture (e.g. esketamine, tobacco, etc.).

Therefore, it's not clear that Dr. Alexander strawmanned anyone in this example.

#### Example 2

Dr. Alexander [wrote](https://astralcodexten.substack.com/p/ivermectin-much-more-than-you-wanted):
   
> if you say anything in favor of ivermectin [...] All the health officials in the world will shout "horse dewormer!" at you and compare you to Josef Mengele. But good doctors aren't supposed to care about such things. Your only goal is to save your patient. Nothing else matters.

Dr. Gelman accepts that "All the health officials in the world" was likely hyperbole, but argues the broader point is a strawman:

> I get it. Alexander is exaggerating for effect. That's a rhetorical device I use all the time, so I'm certainly not gonna slam somebody else for doing it.
> 
> No, my point here is just what I said earlier, that in bending over backward to be fair to the proponents of ivermectin, Alexander has painted himself into the corner in which he is engaging in a ridiculous strawman, not just of opponents of ivermectin, but of the entire public health establishment. Without realizing that his clincher ("Your only goal is to save your patient") contradicts his main argument.
>
> [...]
>
> If "your only goal is to save your patient," then it can be completely rational to speak out against [...] [people who hype dubious cures] and even to use social sanctions if possible.

Dr. Gelman's argument seems to be:

1. Ivermectin proponents are hyping a dubious cure (premise).
2. When "your only goal is to save your patient," one method to do so is to speak out against people who hype dubious cures (premise).
3. Elites speaking out against ivermectin proponents was a rational response (follows from 1 and 2).
4. Therefore, Dr. Alexander strawmanned elites' responses (follows from 3).

However, despite Dr. Alexander agreeing that ivermectin is probably a dubious cure, it seems that he rejects premise 1 because a person looking at the good ivermectin studies might reasonably conclude that it is not a dubious cure, especially because elites seemed to be lying about the studies (i.e. outright denials about positive studies rather than nuanced, scientific denials about parasitic confounds).

It's charitable to think Dr. Alexander was not categorically denying the potential of medical Machiavellianism under some circumstances but that this was irrelevant in this case.

Therefore, it's not clear that Dr. Alexander strawmanned anyone in this example.

For more details of this argument, see the [Steelman Anything topic](/topics/introduction/#steelmanning-one-argument-may-strawman-another).

### Ironmanning: Making an unreasonable argument reasonable

For completeness, ironmanning is when someone makes another person's "unreasonable" argument reasonable. This is the converse of strawmanning. What makes something "unreasonable" on its face is a subjective judgment, so this is not necessarily a fallacy like strawmanning or tinmanning.

In our opinion, accusations of ironmanning aren't very useful unless the accuser is willing to debate what is "unreasonable" and why they judge the subject so.

[Aikin & Casey, 2011]: https://doi.org/10.1007/s10503-010-9199-y 'Aikin, S. F., & Casey, J. (2011). Straw men, weak men, and hollow men. Argumentation, 25(1), 87-105. https://doi.org/10.1007/s10503-010-9199-y'
[Empathy]: https://www.oxfordreference.com/view/10.1093/oi/authority.20110803095750102 'Empathy. Oxford University Press. Retrieved 30 May. 2022, from https://www.oxfordreference.com/view/10.1093/oi/authority.20110803095750102'
[Hansen & Zalta, 2020]: https://plato.stanford.edu/archives/sum2020/entries/fallacies/ 'Hansen, H., & Zalta, E. (Ed.) (2020). Fallacies. The Stanford Encyclopedia of Philosophy (Summer 2020 Edition). https://plato.stanford.edu/archives/sum2020/entries/fallacies/'
[Nye, 2004]: https://doi.org/10.1080/1024529042000301971 'Nye, D. (2004). Regulatory myopia and public health: ‘tough' tobacco control?. Competition & Change, 8(3), 305-321. https://doi.org/10.1080/1024529042000301971'
[Stevens, 2021]: https://doi.org/10.1080/10511431.2021.1897327 'Stevens, K. (2021). Charity for moral reasons?–A defense of the principle of charity in argumentation. Argumentation and Advocacy, 57(2), 67-84. https://doi.org/10.1080/10511431.2021.1897327'
[Stueber & Zalta, 2019]: https://plato.stanford.edu/entries/empathy/ 'Stueber, K., & Zalta, E. (Ed.) (2019). Empathy. The Stanford Encyclopedia of Philosophy (Fall 2019 Edition). https://plato.stanford.edu/archives/fall2019/entries/empathy/'
